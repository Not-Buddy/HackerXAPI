What is Mapple, and what is its primary goal in the context of optimizing parallel programs for distributed heterogeneous systems? 
How does Mapple address the "dimensionality mismatch" between iteration and processor spaces? 
What are the quantitative benefits of using Mapple in terms of mapper code size reduction and performance improvements over expert-written C++ mappers? 
Explain the fundamental difference between Mapple's transformation primitives on the processor space and classical loop transformations. 
What are the three existing interface designs for mapping iteration space to processor space, and what are their respective limitations? 
Describe the decompose primitive and its formal definition, including the optimization problem it aims to solve. 
How does the decompose primitive achieve performance improvements over existing dimensionality-resolution heuristics, and what is the underlying theoretical justification (e.g., in terms of communication volume)? 
What are the key challenges in implementing Mapple by translating it into low-level task-based runtime systems? 
Beyond index mapping, what additional performance optimization features does Mapple offer, as described in Section 7.1? 
What factors influence the performance improvement gained by the decompose primitive, as observed in the experimental results related to aspect ratio, iteration space area, and number of GPUs? 